Machine learning from the view of input data consists of supervised and unsupervised learning. In this traditional facet, the learning models are considered purely all labeled or unlabeled data. However, in many cases, labeling requires a mass effort of human works while it is much easier to collect the data instances only. Furthermore, the unlabeled data in an unsupervised task cannot match with a predefined output. There is a great interest in motivation to combine both types of data in semi-supervised learning whereas we have a massive amount of unlabeled data and only a small proportion of labeled ones.

In this thesis, we present the semi-supervised methods for the binary classification problem using a framework of the generative model. The idea of generative inference is to implicitly predict the label through modeling the joint density of data instances and its corresponding labels. More precisely, we leverage the assumption of mixture model which implied that the distribution of data is laid on different underlying distributions.

What we expect in this thesis are practical learning models that can be straightforwardly handled on hand with affordable complexities and also produce acceptable performances. Therefore, we consider the two different classes of solution. The first traditionally deals with the probabilistic setup of the mixed distributions and solves the problem through the assumptions of prior and conditional distributions. The second solution comes with the more recent inspiration of deriving the graph structure to represent data, the graph-based methods. We construct a graph with vertices from both labeled and unlabeled data. The edges show the relationship between the vertices. In both schemes of solution, we focus on the potential to settle down with the different scales of unlabeled data and identify the underlying distributions. In this meaning, we propose our modification on the origin models and work on several particular setups of each solution to show their abilities to adapt with the condition of semi-supervised learning.